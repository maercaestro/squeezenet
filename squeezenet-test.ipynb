{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26687bac-6b06-48e0-b36e-00a699acb9a9",
   "metadata": {},
   "source": [
    "# Squeezenet Paper : Implementing the 2016 Paper using Pytorch with Flexibility\n",
    "There's a paper here, talking about Squeezenet, which based on my light reading is basically a compressed version of CNN. It's lightweight, with less than 0.5 MB of size, so it must be very good for mobile application and utilized in Edge AI Applications. Before we go any further, let's discuss the paper abstract first\n",
    "\n",
    ">Recent research on deep convolutional neural networks (CNNs) has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple CNN architectures that achieve that accuracy level. With equivalent accuracy, smaller CNN architectures offer at least three advantages: (1)Smaller CNNs require less communication across servers during distributed training. (2) Smaller CNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller CNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small CNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques, we are able to compress SqueezeNet to lessthan 0.5MB (510× smaller than AlexNet).\n",
    ">\n",
    "\n",
    "Ok. The abstract is quite straightforward. It's talking about the issues of current CNN (in 2016 when this paper was released) which has their forcus mostly on the accuracy. But these CNN architecture are bloated with high parameter counts. So they're proposing this SqueezeNet which reduced the parameter count of their CNN and comparing to a famous architecture, the AlexNet (50X smaller). I know a little bit about AlexNet which is the first proof of how effective Deep Learning is against traditional computer vision method during that time. Seeing that they have the same performance as AlexNet with 50x smaller architectures highlights the potential of SqueezeNet as an effective edgeAI implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4aff8-8efb-40e9-a6fb-84c760a2c418",
   "metadata": {},
   "source": [
    "## How did they achieve it?\n",
    "Without going too deep (pun intended) into the paper, let's just go into how they might achieve this. I don't fully read the paper in  it's entirety, just skim and read the key points. And to be frank I use ChatGPT to summarize the points. Hope ChatGPT is not scamming me. From what I read, the key major factor in Squeezenet success is how they managed the filter and the pooling.\n",
    "\n",
    "I've extensively covered about CNN in my previous articles, you can read about it here\n",
    "\n",
    "Part 1:\n",
    "https://medium.com/@maercaestro/siri-belajar-ai-jaringan-neural-berlingkar-convoluted-neural-network-bahagian-1-ef517726609f\n",
    "\n",
    "Part 2:\n",
    "https://medium.com/@maercaestro/siri-belajar-ai-jaringan-neural-berlingkar-convolutional-neural-network-bahagian-2-f19956754288\n",
    "\n",
    "From my article, we know that CNN is adding two process in front of tradtional neural network. The first one is the convoluttional process which allows the network to detect edges and pattern from the image provided, akin to how human and animals process images. The next layer is the pooling layer which reduces the dimensions of the input thus effectively reduce the parameter count coming from the filter. \n",
    "\n",
    "From here, there's actually two issues that I kind of see when I first learn about this\n",
    "\n",
    "**1. The filter size**\n",
    "Although CNN is introduced as a way to effectively process the images compared to traditional Neural Network, the subsequent works on it tends to bloat the filter size. AlexNet itself has 11X11 filter size for it's first convolution layers. This is understandable, since it is a good way to actually learns the spatial/relationship between each pixels and the adjacent pixel. But, high number of filter size will lead to high number of parameter counts, thus leading to inefficiency.\n",
    "\n",
    "**2. Always Pooling after Filter**\n",
    "This is what I question during my first implementation of CNN. They always go to pooling after the convolution. Why do they feel the need to do that? Why not just use only one pooling at the end of the process? That itself seems better\n",
    "\n",
    "So, that's what the author of SqueezeNet did. First, they reduce the size of their filter size, and they remove the unnecessary pooling after each convolution layer. But, to ensure that the spatial information does not loss, they stacked smaller filter size on top of each other. By doing that, they ensure that they can capture all the necessary spatial information, while reducing the parameter size. They called this, their fire module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d534a-14d2-4bad-be18-a57d1e431506",
   "metadata": {},
   "source": [
    "## Let's build this fire module\n",
    "So, in the paper, they present 3 main strategies for their fire module\n",
    "\n",
    "**1. Replace all 3x3 filter (for the first convolutional layer) to 1x1 filter**\n",
    "\n",
    "**2. Replace all input channels to 3x3 filter**\n",
    "\n",
    "**3. Delayed Downsampling (ensure pooling only happened at the last layer**\n",
    "\n",
    "So, that's basically how we want to implement our fire module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c083236b-693d-4042-b672-939905278c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use pytorch for our costum implementation \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FireModule(nn.Module):\n",
    "    \"\"\"\n",
    "    My own implementation of fire module as explain in the Squeezenet paper\n",
    "    Since FireModule is designed in modular form, we can tune it to meet different architecture \n",
    "    that we want depending on the task. In the paper, the firemodel is comes with 3 tunable \n",
    "    parameters\n",
    "\n",
    "    1. The 1x1 squeeze filter (we can determine how many of this we need), we called this sq\n",
    "    2. The 1x1 expand filter (we call this exp1)\n",
    "    3. The 3x3 expand filter (we call this exp3)\n",
    "\n",
    "    Please bear in mind that 1x1 squeeze layer should be smaller than the expand filter\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, sq, exp1, exp3):\n",
    "        super(FireModule,self).__init__()\n",
    "\n",
    "        #we have to enfore constraint to ensure sq1 is always less than exp1+exp3\n",
    "        if sq >= (exp1+exp3):\n",
    "            raise ValueError(f\"squeeze layer {sq} should always be smaller that {exp1+exp3}\")\n",
    "\n",
    "        # Squeeze Layer (1×1 convolution)\n",
    "        self.squeeze = nn.Conv2d(in_channels, sq, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU() #always follow with ReLU activation functon\n",
    "\n",
    "        # Expand Layer (1×1 and 3×3 convolutions)\n",
    "        self.expand1x1 = nn.Conv2d(sq, exp1, kernel_size=1)\n",
    "        self.expand3x3 = nn.Conv2d(sq, exp3, kernel_size=3, padding=1)\n",
    "        self.expand_activation = nn.ReLU() #always follow with ReLU activation functon\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze(x))  # Squeeze\n",
    "        x1 = self.expand_activation(self.expand1x1(x))  # Expand (1×1)\n",
    "        x3 = self.expand_activation(self.expand3x3(x))  # Expand (3×3)\n",
    "        return torch.cat([x1, x3], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a223b1-d69b-4452-ac00-e89a43190e31",
   "metadata": {},
   "source": [
    "## Let's Test SqueezeNet Theoretically via Receptive Field\n",
    "So there's a new term that I just learn. We know that AlexNet has a large number of filters (11x11) due to the fact that it wants to capture the spatial information and relationship between it's pixel. But it resulted in high parameter counts. SqueezeNet aims to reduce this parameter counts by stacking multiple 3x3 filters on top of each other to capture that spatial information instead of using a larger filter early on. So how do we know SqueezeNet was able to match AlexNet performance with that strategy? Let's test it's **receptive field**.\n",
    "\n",
    "According to Wikipedia, the receptive field (of a biological neuron) is **“the portion of the sensory space that can elicit neuronal responses, when stimulated”**\n",
    "\n",
    "We can denote the equation of the receptive field as below\n",
    "\n",
    "$$\n",
    "r(i-1) = s_i \\times r_i + (k_i - s_i)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **$ r(i-1) $** = Receptive field of the previous layer.\n",
    "- **$ r_i $** = Receptive field of the current layer.\n",
    "- **$ s_i $** = Stride of the current layer.\n",
    "- **$ k_i $** = Kernel size of the current layer.\n",
    "\n",
    "\n",
    "So, with this equation, we can use it to compare the receptive field of both AlexNet vs the SqueezeNet and see whether SqueezeNet strategy has its merits. So let's test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36dc13f-a100-41a5-a270-2cfce7c5f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we define the equation to calculate the receptive field\n",
    "def compute_receptive_field(layers):\n",
    "    \"\"\"\n",
    "    Compute the receptive field using the backward approach.\n",
    "    \n",
    "    layers: list of (layer_name, kernel_size, stride),\n",
    "            ordered from the FIRST layer to the LAST layer.\n",
    "            \n",
    "    We'll reverse this list internally and apply:\n",
    "        r_(i-1) = s_i * r_i + (k_i - s_i)\n",
    "    \n",
    "    Returns:\n",
    "        final_rf: The receptive field seen at the input for the LAST layer.\n",
    "        rf_per_layer: A list of (layer_name, receptive_field) from last to first.\n",
    "    \"\"\"\n",
    "    # Start with receptive field of size 1 at the last layer\n",
    "    r = 1\n",
    "    rf_per_layer = []\n",
    "    \n",
    "    # Process from last to first\n",
    "    for (layer_name, k, s) in reversed(layers):\n",
    "        r = s * r + (k - s)\n",
    "        rf_per_layer.append((layer_name, r))\n",
    "    \n",
    "    # Reverse rf_per_layer so it's in forward order\n",
    "    rf_per_layer.reverse()\n",
    "    return r, rf_per_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbdd09c-277a-4042-8043-9a372af87c50",
   "metadata": {},
   "source": [
    "### Let's test this on AlexNet\n",
    "We will test this equation on AlexNet, but we're only talking on the actitecture itself, not building the entire model in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5660f4-6bbd-4bf7-bbe9-b66608dd4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_layers = [\n",
    "    (\"conv1\", 11, 4),   # Conv1\n",
    "    (\"pool1\", 3, 2),    # MaxPool1\n",
    "    (\"conv2\", 5, 1),    # Conv2\n",
    "    (\"pool2\", 3, 2),    # MaxPool2\n",
    "    (\"conv3\", 3, 1),    # Conv3\n",
    "    (\"conv4\", 3, 1),    # Conv4\n",
    "    (\"conv5\", 3, 1),    # Conv5\n",
    "    (\"pool3\", 3, 2)     # MaxPool3\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6723163-28f6-4623-984e-b70269262084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet Receptive Field (Ignoring Padding): 195\n",
      "Layer-by-Layer Growth (From Last to First):\n",
      "  conv1 -> RF = 195\n",
      "  pool1 -> RF = 47\n",
      "  conv2 -> RF = 23\n",
      "  pool2 -> RF = 19\n",
      "  conv3 -> RF = 9\n",
      "  conv4 -> RF = 7\n",
      "  conv5 -> RF = 5\n",
      "  pool3 -> RF = 3\n"
     ]
    }
   ],
   "source": [
    "alex_rf, alex_rf_layers = compute_receptive_field(alexnet_layers)\n",
    "print(\"AlexNet Receptive Field (Ignoring Padding):\", alex_rf)\n",
    "print(\"Layer-by-Layer Growth (From Last to First):\")\n",
    "for layer_name, rf_val in alex_rf_layers:\n",
    "    print(f\"  {layer_name} -> RF = {rf_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a993bb-f264-4720-bd4c-9faf8ab7bdf4",
   "metadata": {},
   "source": [
    "### Now, let's compare with SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b6deff-e280-4044-8387-748289635778",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezenet_layers = [\n",
    "    (\"conv1\", 7, 2),       # Conv1\n",
    "    (\"pool1\", 3, 2),       # MaxPool (after Conv1)\n",
    "    \n",
    "    # Fire2 - expand3x3\n",
    "    (\"fire2\", 3, 1),\n",
    "    # Fire3 - expand3x3\n",
    "    (\"fire3\", 3, 1),\n",
    "    # Fire4 - expand3x3\n",
    "    (\"fire4\", 3, 1),\n",
    "    (\"pool4\", 3, 2),       # MaxPool (after Fire4)\n",
    "    \n",
    "    # Fire5, Fire6, Fire7, Fire8 - expand3x3\n",
    "    (\"fire5\", 3, 1),\n",
    "    (\"fire6\", 3, 1),\n",
    "    (\"fire7\", 3, 1),\n",
    "    (\"fire8\", 3, 1),\n",
    "    (\"pool8\", 3, 2),       # MaxPool (after Fire8)\n",
    "    \n",
    "    # Fire9 - expand3x3\n",
    "    (\"fire9\", 3, 1),\n",
    "    \n",
    "    # Final conv layer\n",
    "    (\"conv10\", 1, 1)       # This 1×1 kernel doesn't expand RF, but let's include it for completeness\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b48bdb-157b-4026-8286-a8b05118dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SqueezeNet Receptive Field (Ignoring Padding): 155\n",
      " Layer-by-Layer Growth (From Last to First):\n",
      "  conv1 -> RF = 155\n",
      "  pool1 -> RF = 75\n",
      "  fire2 -> RF = 37\n",
      "  fire3 -> RF = 35\n",
      "  fire4 -> RF = 33\n",
      "  pool4 -> RF = 31\n",
      "  fire5 -> RF = 15\n",
      "  fire6 -> RF = 13\n",
      "  fire7 -> RF = 11\n",
      "  fire8 -> RF = 9\n",
      "  pool8 -> RF = 7\n",
      "  fire9 -> RF = 3\n",
      "  conv10 -> RF = 1\n"
     ]
    }
   ],
   "source": [
    "squeeze_rf, squeeze_rf_layers = compute_receptive_field(squeezenet_layers)\n",
    "print(\"\\n SqueezeNet Receptive Field (Ignoring Padding):\", squeeze_rf)\n",
    "print(\" Layer-by-Layer Growth (From Last to First):\")\n",
    "for layer_name, rf_val in squeeze_rf_layers:\n",
    "    print(f\"  {layer_name} -> RF = {rf_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bae5de-1a3a-4c1b-8c52-d5fb70665ef6",
   "metadata": {},
   "source": [
    "Based on what we see above, it seems like SqueezeNet has 45 less receptive field compared to AlexNet. That doesn't seems good seems it might impact the performance of the model. But seeing that SqueezeNet has 50x less parameter counts but only around 20% less receptive seems a good tradeoff. But this is just on theoretical level, let's test it on real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada928f4-1c46-4012-a15a-5c22b3a148bd",
   "metadata": {},
   "source": [
    "## Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894e4d04-5d4a-40b3-ae68-0bcb80e787ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20375d93-692d-4ff2-bdc7-b848185b7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimized Fire module with enforced constraint:\n",
    "    s1x1 < e1x1 + e3x3 (Squeeze filters must be fewer than Expand filters).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, s1x1, e1x1, e3x3):\n",
    "        super(FireModule, self).__init__()\n",
    "\n",
    "        # Enforce constraint\n",
    "        if s1x1 >= (e1x1 + e3x3):\n",
    "            raise ValueError(f\"Invalid Fire Module: s1x1 ({s1x1}) must be smaller than e1x1 + e3x3 ({e1x1 + e3x3}).\")\n",
    "\n",
    "        # Squeeze Layer (1×1)\n",
    "        self.squeeze = nn.Conv2d(in_channels, s1x1, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU()\n",
    "\n",
    "        # Expand Layer (1×1 and 3×3)\n",
    "        self.expand1x1 = nn.Conv2d(s1x1, e1x1, kernel_size=1)\n",
    "        self.expand3x3 = nn.Conv2d(s1x1, e3x3, kernel_size=3, padding=1)\n",
    "        self.expand_activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze(x))  # Squeeze\n",
    "        x1 = self.expand_activation(self.expand1x1(x))  # Expand (1×1)\n",
    "        x3 = self.expand_activation(self.expand3x3(x))  # Expand (3×3)\n",
    "        return torch.cat([x1, x3], dim=1)  # Concatenate across channels\n",
    "\n",
    "\n",
    "class FlexibleSqueezeNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible SqueezeNet implementation with Fire Modules and optional pooling layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10, fire_configs=None, pooling_layers=None):\n",
    "        super(FlexibleSqueezeNet, self).__init__()\n",
    "        \n",
    "        # Default config: Similar to SqueezeNet v1.0 (but smaller to handle CIFAR-10 quickly)\n",
    "        if fire_configs is None:\n",
    "            fire_configs = [\n",
    "                (16, 32, 32),  # Fire2\n",
    "                (16, 32, 32),  # Fire3\n",
    "                (32, 64, 64),  # Fire4\n",
    "                (32, 64, 64),  # Fire5\n",
    "                (48, 96, 96),  # Fire6\n",
    "                (48, 96, 96),  # Fire7\n",
    "                (64, 128, 128),# Fire8\n",
    "                (64, 128, 128) # Fire9\n",
    "            ]\n",
    "\n",
    "        # Where to apply max pooling (delayed pooling approach)\n",
    "        if pooling_layers is None:\n",
    "            # This list must match length of fire_configs\n",
    "            pooling_layers = [False, True, False, True, False, True, False, True]\n",
    "\n",
    "        # Enforce constraints for each Fire module\n",
    "        for s1x1, e1x1, e3x3 in fire_configs:\n",
    "            if s1x1 >= (e1x1 + e3x3):\n",
    "                raise ValueError(f\"Invalid Fire Module: s1x1 ({s1x1}) >= e1x1 + e3x3 ({e1x1 + e3x3})\")\n",
    "\n",
    "        # Initial layer: smaller for CIFAR-10 (32x32)\n",
    "        # We'll use kernel_size=3, stride=1 to keep more spatial info\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instead of a big maxpool, let's just do a small one here\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        # Build Fire modules\n",
    "        self.fire_layers = nn.ModuleList()\n",
    "        in_channels = 96\n",
    "        for i, (s1x1, e1x1, e3x3) in enumerate(fire_configs):\n",
    "            self.fire_layers.append(FireModule(in_channels, s1x1, e1x1, e3x3))\n",
    "            in_channels = e1x1 + e3x3  # update for next Fire module\n",
    "            if pooling_layers[i]:\n",
    "                # Another small pooling to reduce resolution\n",
    "                self.fire_layers.append(nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True))\n",
    "\n",
    "        # Final conv to match num_classes\n",
    "        self.conv10 = nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        for layer in self.fire_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "\n",
    "    \n",
    "        x = self.avgpool(x)\n",
    "\n",
    "    \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f5ae7b-82e7-414a-bf3b-04ec7cd60efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using device: mps\n",
      "Epoch [1/50]\n",
      "  Train Loss: 2.2435 | Train Acc: 13.89%\n",
      "  Test  Loss: 2.1771  | Test  Acc: 16.70%\n",
      "--------------------------------------------------\n",
      "Epoch [2/50]\n",
      "  Train Loss: 2.1593 | Train Acc: 18.96%\n",
      "  Test  Loss: 2.0693  | Test  Acc: 23.65%\n",
      "--------------------------------------------------\n",
      "Epoch [3/50]\n",
      "  Train Loss: 1.9965 | Train Acc: 28.19%\n",
      "  Test  Loss: 1.9075  | Test  Acc: 32.04%\n",
      "--------------------------------------------------\n",
      "Epoch [4/50]\n",
      "  Train Loss: 1.8803 | Train Acc: 33.35%\n",
      "  Test  Loss: 1.8882  | Test  Acc: 36.14%\n",
      "--------------------------------------------------\n",
      "Epoch [5/50]\n",
      "  Train Loss: 1.8038 | Train Acc: 36.56%\n",
      "  Test  Loss: 1.7551  | Test  Acc: 39.20%\n",
      "--------------------------------------------------\n",
      "Epoch [6/50]\n",
      "  Train Loss: 1.7437 | Train Acc: 38.91%\n",
      "  Test  Loss: 1.6376  | Test  Acc: 41.74%\n",
      "--------------------------------------------------\n",
      "Epoch [7/50]\n",
      "  Train Loss: 1.6185 | Train Acc: 41.12%\n",
      "  Test  Loss: 1.6038  | Test  Acc: 41.17%\n",
      "--------------------------------------------------\n",
      "Epoch [8/50]\n",
      "  Train Loss: 1.5607 | Train Acc: 43.00%\n",
      "  Test  Loss: 1.5908  | Test  Acc: 41.61%\n",
      "--------------------------------------------------\n",
      "Epoch [9/50]\n",
      "  Train Loss: 1.4440 | Train Acc: 50.40%\n",
      "  Test  Loss: 1.6370  | Test  Acc: 44.09%\n",
      "--------------------------------------------------\n",
      "Epoch [10/50]\n",
      "  Train Loss: 1.3763 | Train Acc: 52.62%\n",
      "  Test  Loss: 1.3088  | Test  Acc: 54.81%\n",
      "--------------------------------------------------\n",
      "Epoch [11/50]\n",
      "  Train Loss: 1.3333 | Train Acc: 53.47%\n",
      "  Test  Loss: 1.2815  | Test  Acc: 54.81%\n",
      "--------------------------------------------------\n",
      "Epoch [12/50]\n",
      "  Train Loss: 1.2899 | Train Acc: 55.02%\n",
      "  Test  Loss: 1.2594  | Test  Acc: 55.08%\n",
      "--------------------------------------------------\n",
      "Epoch [13/50]\n",
      "  Train Loss: 1.2402 | Train Acc: 56.51%\n",
      "  Test  Loss: 1.1620  | Test  Acc: 58.91%\n",
      "--------------------------------------------------\n",
      "Epoch [14/50]\n",
      "  Train Loss: 1.2098 | Train Acc: 57.46%\n",
      "  Test  Loss: 1.1480  | Test  Acc: 59.55%\n",
      "--------------------------------------------------\n",
      "Epoch [15/50]\n",
      "  Train Loss: 1.1717 | Train Acc: 58.63%\n",
      "  Test  Loss: 1.1199  | Test  Acc: 60.60%\n",
      "--------------------------------------------------\n",
      "Epoch [16/50]\n",
      "  Train Loss: 1.1347 | Train Acc: 60.26%\n",
      "  Test  Loss: 1.1160  | Test  Acc: 60.01%\n",
      "--------------------------------------------------\n",
      "Epoch [17/50]\n",
      "  Train Loss: 1.1344 | Train Acc: 60.03%\n",
      "  Test  Loss: 1.1252  | Test  Acc: 60.46%\n",
      "--------------------------------------------------\n",
      "Epoch [18/50]\n",
      "  Train Loss: 1.0834 | Train Acc: 61.82%\n",
      "  Test  Loss: 1.0461  | Test  Acc: 62.53%\n",
      "--------------------------------------------------\n",
      "Epoch [19/50]\n",
      "  Train Loss: 1.0647 | Train Acc: 62.52%\n",
      "  Test  Loss: 1.0217  | Test  Acc: 64.04%\n",
      "--------------------------------------------------\n",
      "Epoch [20/50]\n",
      "  Train Loss: 1.0392 | Train Acc: 63.42%\n",
      "  Test  Loss: 0.9802  | Test  Acc: 65.31%\n",
      "--------------------------------------------------\n",
      "Epoch [21/50]\n",
      "  Train Loss: 1.0145 | Train Acc: 64.15%\n",
      "  Test  Loss: 0.9722  | Test  Acc: 65.55%\n",
      "--------------------------------------------------\n",
      "Epoch [22/50]\n",
      "  Train Loss: 0.9977 | Train Acc: 64.86%\n",
      "  Test  Loss: 0.9727  | Test  Acc: 65.55%\n",
      "--------------------------------------------------\n",
      "Epoch [23/50]\n",
      "  Train Loss: 0.9720 | Train Acc: 65.67%\n",
      "  Test  Loss: 0.9601  | Test  Acc: 66.37%\n",
      "--------------------------------------------------\n",
      "Epoch [24/50]\n",
      "  Train Loss: 0.9673 | Train Acc: 65.89%\n",
      "  Test  Loss: 0.9770  | Test  Acc: 65.98%\n",
      "--------------------------------------------------\n",
      "Epoch [25/50]\n",
      "  Train Loss: 0.9405 | Train Acc: 66.88%\n",
      "  Test  Loss: 0.9473  | Test  Acc: 66.29%\n",
      "--------------------------------------------------\n",
      "Epoch [26/50]\n",
      "  Train Loss: 0.9289 | Train Acc: 67.25%\n",
      "  Test  Loss: 0.9097  | Test  Acc: 67.69%\n",
      "--------------------------------------------------\n",
      "Epoch [27/50]\n",
      "  Train Loss: 0.9204 | Train Acc: 67.65%\n",
      "  Test  Loss: 1.0031  | Test  Acc: 65.64%\n",
      "--------------------------------------------------\n",
      "Epoch [28/50]\n",
      "  Train Loss: 0.8930 | Train Acc: 68.36%\n",
      "  Test  Loss: 0.8863  | Test  Acc: 68.72%\n",
      "--------------------------------------------------\n",
      "Epoch [29/50]\n",
      "  Train Loss: 0.8800 | Train Acc: 68.74%\n",
      "  Test  Loss: 0.8761  | Test  Acc: 69.13%\n",
      "--------------------------------------------------\n",
      "Epoch [30/50]\n",
      "  Train Loss: 0.8695 | Train Acc: 69.40%\n",
      "  Test  Loss: 0.8650  | Test  Acc: 69.17%\n",
      "--------------------------------------------------\n",
      "Epoch [31/50]\n",
      "  Train Loss: 0.8666 | Train Acc: 69.33%\n",
      "  Test  Loss: 0.8797  | Test  Acc: 68.97%\n",
      "--------------------------------------------------\n",
      "Epoch [32/50]\n",
      "  Train Loss: 0.8502 | Train Acc: 69.81%\n",
      "  Test  Loss: 0.8647  | Test  Acc: 69.62%\n",
      "--------------------------------------------------\n",
      "Epoch [33/50]\n",
      "  Train Loss: 0.8412 | Train Acc: 70.21%\n",
      "  Test  Loss: 0.8411  | Test  Acc: 70.28%\n",
      "--------------------------------------------------\n",
      "Epoch [34/50]\n",
      "  Train Loss: 0.8326 | Train Acc: 70.35%\n",
      "  Test  Loss: 0.8508  | Test  Acc: 69.99%\n",
      "--------------------------------------------------\n",
      "Epoch [35/50]\n",
      "  Train Loss: 0.8129 | Train Acc: 71.11%\n",
      "  Test  Loss: 0.8550  | Test  Acc: 69.84%\n",
      "--------------------------------------------------\n",
      "Epoch [36/50]\n",
      "  Train Loss: 0.8144 | Train Acc: 71.07%\n",
      "  Test  Loss: 0.8376  | Test  Acc: 70.05%\n",
      "--------------------------------------------------\n",
      "Epoch [37/50]\n",
      "  Train Loss: 0.8149 | Train Acc: 71.13%\n",
      "  Test  Loss: 0.8104  | Test  Acc: 71.40%\n",
      "--------------------------------------------------\n",
      "Epoch [38/50]\n",
      "  Train Loss: 0.7976 | Train Acc: 71.49%\n",
      "  Test  Loss: 0.8369  | Test  Acc: 70.19%\n",
      "--------------------------------------------------\n",
      "Epoch [39/50]\n",
      "  Train Loss: 0.7351 | Train Acc: 74.16%\n",
      "  Test  Loss: 0.5960  | Test  Acc: 80.28%\n",
      "--------------------------------------------------\n",
      "Epoch [40/50]\n",
      "  Train Loss: 0.5797 | Train Acc: 80.14%\n",
      "  Test  Loss: 0.5771  | Test  Acc: 80.23%\n",
      "--------------------------------------------------\n",
      "Epoch [41/50]\n",
      "  Train Loss: 0.5748 | Train Acc: 80.24%\n",
      "  Test  Loss: 0.6013  | Test  Acc: 79.74%\n",
      "--------------------------------------------------\n",
      "Epoch [42/50]\n",
      "  Train Loss: 0.5563 | Train Acc: 80.92%\n",
      "  Test  Loss: 0.5684  | Test  Acc: 80.39%\n",
      "--------------------------------------------------\n",
      "Epoch [43/50]\n",
      "  Train Loss: 0.5529 | Train Acc: 81.01%\n",
      "  Test  Loss: 0.5784  | Test  Acc: 80.46%\n",
      "--------------------------------------------------\n",
      "Epoch [44/50]\n",
      "  Train Loss: 0.5420 | Train Acc: 81.29%\n",
      "  Test  Loss: 0.5408  | Test  Acc: 81.62%\n",
      "--------------------------------------------------\n",
      "Epoch [45/50]\n",
      "  Train Loss: 0.5365 | Train Acc: 81.38%\n",
      "  Test  Loss: 0.6021  | Test  Acc: 79.47%\n",
      "--------------------------------------------------\n",
      "Epoch [46/50]\n",
      "  Train Loss: 0.5270 | Train Acc: 81.84%\n",
      "  Test  Loss: 0.5478  | Test  Acc: 81.47%\n",
      "--------------------------------------------------\n",
      "Epoch [47/50]\n",
      "  Train Loss: 0.5256 | Train Acc: 81.75%\n",
      "  Test  Loss: 0.6099  | Test  Acc: 79.62%\n",
      "--------------------------------------------------\n",
      "Epoch [48/50]\n",
      "  Train Loss: 0.5166 | Train Acc: 82.29%\n",
      "  Test  Loss: 0.5655  | Test  Acc: 81.24%\n",
      "--------------------------------------------------\n",
      "Epoch [49/50]\n",
      "  Train Loss: 0.5086 | Train Acc: 82.49%\n",
      "  Test  Loss: 0.5308  | Test  Acc: 81.77%\n",
      "--------------------------------------------------\n",
      "Epoch [50/50]\n",
      "  Train Loss: 0.5027 | Train Acc: 82.46%\n",
      "  Test  Loss: 0.5392  | Test  Acc: 81.82%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "########################################\n",
    "# 1. Data Loading for CIFAR-10\n",
    "########################################\n",
    "\n",
    "# Recommended CIFAR-10 data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "########################################\n",
    "# 2. Define the Fire Module\n",
    "########################################\n",
    "\n",
    "class Fire(nn.Module):\n",
    "    \"\"\"\n",
    "    A slightly modified 'Fire' module (same concept from official SqueezeNet).\n",
    "    Squeeze -> Expand(1x1) + Expand(3x3)\n",
    "    \"\"\"\n",
    "    def __init__(self, inplanes, squeeze_planes, expand1x1_planes, expand3x3_planes):\n",
    "        super().__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        out1x1 = self.expand1x1_activation(self.expand1x1(x))\n",
    "        out3x3 = self.expand3x3_activation(self.expand3x3(x))\n",
    "        return torch.cat([out1x1, out3x3], dim=1)\n",
    "\n",
    "\n",
    "########################################\n",
    "# 3. Define a SqueezeNet Variant for CIFAR-10\n",
    "########################################\n",
    "\n",
    "class SqueezeNetCIFAR(nn.Module):\n",
    "    \"\"\"\n",
    "    A SqueezeNet-like architecture tuned for 32x32 inputs:\n",
    "    - Smaller initial kernel, stride=1\n",
    "    - Fewer aggressive max pools\n",
    "    - Final conv to 10 classes\n",
    "    - Global avg pool\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial conv: smaller kernel and stride=1 for CIFAR-10\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # was 7x7, stride=2 in original\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Optional small pooling to reduce dimension a bit\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # from 32x32 -> 16x16\n",
    "            \n",
    "            # Fire modules\n",
    "            Fire(64, 16, 64, 64),   # out = 128\n",
    "            Fire(128, 16, 64, 64),  # out = 128\n",
    "            \n",
    "            # Another max pool (optional)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 16x16 -> 8x8\n",
    "            \n",
    "            Fire(128, 32, 128, 128), # out = 256\n",
    "            Fire(256, 32, 128, 128), # out = 256\n",
    "            \n",
    "            # Another max pool (optional)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 8x8 -> 4x4\n",
    "            \n",
    "            Fire(256, 48, 192, 192), # out = 384\n",
    "            Fire(384, 48, 192, 192), # out = 384\n",
    "            \n",
    "            # Another max pool (optional)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 4x4 -> 2x2\n",
    "            \n",
    "            Fire(384, 64, 256, 256), # out = 512\n",
    "        )\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1),  # 512 -> 10\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # Initialization similar to official squeezenet\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m is self.classifier[1]:  # final conv\n",
    "                    nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        # Flatten to [N, num_classes]\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "\n",
    "########################################\n",
    "# 4. Instantiate Model, Loss, Optimizer\n",
    "########################################\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = SqueezeNetCIFAR(num_classes=10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "########################################\n",
    "# 5. Training and Evaluation Functions\n",
    "########################################\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        total_correct += preds.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            total_correct += preds.eq(labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "########################################\n",
    "# 6. Main Training Loop\n",
    "########################################\n",
    "\n",
    "num_epochs = 50  # Increase if you want better convergence\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Test  Loss: {test_loss:.4f}  | Test  Acc: {test_acc:.2f}%\")\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2083f343-24a5-4ca4-8ec9-b5c571db3a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Available: True\n",
      "MPS Built: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "print(f\"MPS Available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS Built: {torch.backends.mps.is_built()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca7faef-a2cd-4981-83ee-84dbe1788320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/50]\n",
      "  Train Loss: 2.2097 | Train Acc: 16.48%\n",
      "  Test  Loss: 2.2218  | Test  Acc: 19.76%\n",
      "--------------------------------------------------\n",
      "Epoch [2/50]\n",
      "  Train Loss: 2.1458 | Train Acc: 21.46%\n",
      "  Test  Loss: 2.0936  | Test  Acc: 24.64%\n",
      "--------------------------------------------------\n",
      "Epoch [3/50]\n",
      "  Train Loss: 2.0462 | Train Acc: 24.54%\n",
      "  Test  Loss: 1.9165  | Test  Acc: 29.94%\n",
      "--------------------------------------------------\n",
      "Epoch [4/50]\n",
      "  Train Loss: 1.9320 | Train Acc: 28.54%\n",
      "  Test  Loss: 1.7919  | Test  Acc: 34.17%\n",
      "--------------------------------------------------\n",
      "Epoch [5/50]\n",
      "  Train Loss: 1.8205 | Train Acc: 33.15%\n",
      "  Test  Loss: 1.7011  | Test  Acc: 39.12%\n",
      "--------------------------------------------------\n",
      "Epoch [6/50]\n",
      "  Train Loss: 1.7394 | Train Acc: 37.02%\n",
      "  Test  Loss: 1.6273  | Test  Acc: 41.64%\n",
      "--------------------------------------------------\n",
      "Epoch [7/50]\n",
      "  Train Loss: 1.6894 | Train Acc: 39.60%\n",
      "  Test  Loss: 1.5761  | Test  Acc: 44.55%\n",
      "--------------------------------------------------\n",
      "Epoch [8/50]\n",
      "  Train Loss: 1.6223 | Train Acc: 42.41%\n",
      "  Test  Loss: 1.5265  | Test  Acc: 46.46%\n",
      "--------------------------------------------------\n",
      "Epoch [9/50]\n",
      "  Train Loss: 1.5566 | Train Acc: 44.89%\n",
      "  Test  Loss: 1.4290  | Test  Acc: 49.00%\n",
      "--------------------------------------------------\n",
      "Epoch [10/50]\n",
      "  Train Loss: 1.4269 | Train Acc: 48.95%\n",
      "  Test  Loss: 1.2940  | Test  Acc: 53.55%\n",
      "--------------------------------------------------\n",
      "Epoch [11/50]\n",
      "  Train Loss: 1.3749 | Train Acc: 50.50%\n",
      "  Test  Loss: 1.2790  | Test  Acc: 53.42%\n",
      "--------------------------------------------------\n",
      "Epoch [12/50]\n",
      "  Train Loss: 1.3346 | Train Acc: 52.17%\n",
      "  Test  Loss: 1.2796  | Test  Acc: 54.65%\n",
      "--------------------------------------------------\n",
      "Epoch [13/50]\n",
      "  Train Loss: 1.3001 | Train Acc: 53.59%\n",
      "  Test  Loss: 1.2055  | Test  Acc: 56.89%\n",
      "--------------------------------------------------\n",
      "Epoch [14/50]\n",
      "  Train Loss: 1.2792 | Train Acc: 54.44%\n",
      "  Test  Loss: 1.1737  | Test  Acc: 58.08%\n",
      "--------------------------------------------------\n",
      "Epoch [15/50]\n",
      "  Train Loss: 1.2466 | Train Acc: 55.86%\n",
      "  Test  Loss: 1.1624  | Test  Acc: 58.65%\n",
      "--------------------------------------------------\n",
      "Epoch [16/50]\n",
      "  Train Loss: 1.2174 | Train Acc: 56.82%\n",
      "  Test  Loss: 1.1510  | Test  Acc: 59.49%\n",
      "--------------------------------------------------\n",
      "Epoch [17/50]\n",
      "  Train Loss: 1.1875 | Train Acc: 57.69%\n",
      "  Test  Loss: 1.1027  | Test  Acc: 60.49%\n",
      "--------------------------------------------------\n",
      "Epoch [18/50]\n",
      "  Train Loss: 1.1610 | Train Acc: 58.87%\n",
      "  Test  Loss: 1.0932  | Test  Acc: 60.64%\n",
      "--------------------------------------------------\n",
      "Epoch [19/50]\n",
      "  Train Loss: 1.1404 | Train Acc: 59.52%\n",
      "  Test  Loss: 1.1361  | Test  Acc: 60.55%\n",
      "--------------------------------------------------\n",
      "Epoch [20/50]\n",
      "  Train Loss: 1.1211 | Train Acc: 60.45%\n",
      "  Test  Loss: 1.0579  | Test  Acc: 62.74%\n",
      "--------------------------------------------------\n",
      "Epoch [21/50]\n",
      "  Train Loss: 1.1055 | Train Acc: 61.25%\n",
      "  Test  Loss: 1.0526  | Test  Acc: 63.01%\n",
      "--------------------------------------------------\n",
      "Epoch [22/50]\n",
      "  Train Loss: 1.0887 | Train Acc: 61.82%\n",
      "  Test  Loss: 1.0712  | Test  Acc: 62.39%\n",
      "--------------------------------------------------\n",
      "Epoch [23/50]\n",
      "  Train Loss: 1.0750 | Train Acc: 62.30%\n",
      "  Test  Loss: 1.0243  | Test  Acc: 63.72%\n",
      "--------------------------------------------------\n",
      "Epoch [24/50]\n",
      "  Train Loss: 1.0560 | Train Acc: 62.81%\n",
      "  Test  Loss: 1.0142  | Test  Acc: 64.14%\n",
      "--------------------------------------------------\n",
      "Epoch [25/50]\n",
      "  Train Loss: 1.0537 | Train Acc: 63.09%\n",
      "  Test  Loss: 1.0077  | Test  Acc: 64.51%\n",
      "--------------------------------------------------\n",
      "Epoch [26/50]\n",
      "  Train Loss: 1.0353 | Train Acc: 63.72%\n",
      "  Test  Loss: 1.0626  | Test  Acc: 62.33%\n",
      "--------------------------------------------------\n",
      "Epoch [27/50]\n",
      "  Train Loss: 1.0144 | Train Acc: 64.54%\n",
      "  Test  Loss: 0.9649  | Test  Acc: 65.81%\n",
      "--------------------------------------------------\n",
      "Epoch [28/50]\n",
      "  Train Loss: 1.0155 | Train Acc: 64.46%\n",
      "  Test  Loss: 1.0010  | Test  Acc: 65.03%\n",
      "--------------------------------------------------\n",
      "Epoch [29/50]\n",
      "  Train Loss: 0.9963 | Train Acc: 65.32%\n",
      "  Test  Loss: 0.9231  | Test  Acc: 67.32%\n",
      "--------------------------------------------------\n",
      "Epoch [30/50]\n",
      "  Train Loss: 0.9797 | Train Acc: 65.66%\n",
      "  Test  Loss: 0.9352  | Test  Acc: 67.22%\n",
      "--------------------------------------------------\n",
      "Epoch [31/50]\n",
      "  Train Loss: 0.9607 | Train Acc: 66.52%\n",
      "  Test  Loss: 0.9171  | Test  Acc: 68.46%\n",
      "--------------------------------------------------\n",
      "Epoch [32/50]\n",
      "  Train Loss: 0.9598 | Train Acc: 66.35%\n",
      "  Test  Loss: 0.8868  | Test  Acc: 69.11%\n",
      "--------------------------------------------------\n",
      "Epoch [33/50]\n",
      "  Train Loss: 0.9584 | Train Acc: 66.56%\n",
      "  Test  Loss: 0.9273  | Test  Acc: 67.97%\n",
      "--------------------------------------------------\n",
      "Epoch [34/50]\n",
      "  Train Loss: 0.9435 | Train Acc: 67.22%\n",
      "  Test  Loss: 0.9165  | Test  Acc: 68.20%\n",
      "--------------------------------------------------\n",
      "Epoch [35/50]\n",
      "  Train Loss: 0.9343 | Train Acc: 67.61%\n",
      "  Test  Loss: 0.9117  | Test  Acc: 68.03%\n",
      "--------------------------------------------------\n",
      "Epoch [36/50]\n",
      "  Train Loss: 0.9215 | Train Acc: 68.09%\n",
      "  Test  Loss: 0.8505  | Test  Acc: 70.43%\n",
      "--------------------------------------------------\n",
      "Epoch [37/50]\n",
      "  Train Loss: 0.9126 | Train Acc: 68.30%\n",
      "  Test  Loss: 0.8565  | Test  Acc: 70.25%\n",
      "--------------------------------------------------\n",
      "Epoch [38/50]\n",
      "  Train Loss: 0.9114 | Train Acc: 68.38%\n",
      "  Test  Loss: 0.9237  | Test  Acc: 67.95%\n",
      "--------------------------------------------------\n",
      "Epoch [39/50]\n",
      "  Train Loss: 0.8947 | Train Acc: 68.84%\n",
      "  Test  Loss: 0.8520  | Test  Acc: 70.79%\n",
      "--------------------------------------------------\n",
      "Epoch [40/50]\n",
      "  Train Loss: 0.8884 | Train Acc: 69.21%\n",
      "  Test  Loss: 0.8535  | Test  Acc: 71.00%\n",
      "--------------------------------------------------\n",
      "Epoch [41/50]\n",
      "  Train Loss: 0.8778 | Train Acc: 69.55%\n",
      "  Test  Loss: 0.8814  | Test  Acc: 69.28%\n",
      "--------------------------------------------------\n",
      "Epoch [42/50]\n",
      "  Train Loss: 0.8666 | Train Acc: 69.97%\n",
      "  Test  Loss: 0.8560  | Test  Acc: 70.33%\n",
      "--------------------------------------------------\n",
      "Epoch [43/50]\n",
      "  Train Loss: 0.8630 | Train Acc: 70.11%\n",
      "  Test  Loss: 0.8229  | Test  Acc: 71.52%\n",
      "--------------------------------------------------\n",
      "Epoch [44/50]\n",
      "  Train Loss: 0.8562 | Train Acc: 70.30%\n",
      "  Test  Loss: 0.8706  | Test  Acc: 70.08%\n",
      "--------------------------------------------------\n",
      "Epoch [45/50]\n",
      "  Train Loss: 0.8522 | Train Acc: 70.68%\n",
      "  Test  Loss: 0.8044  | Test  Acc: 72.61%\n",
      "--------------------------------------------------\n",
      "Epoch [46/50]\n",
      "  Train Loss: 0.8409 | Train Acc: 70.85%\n",
      "  Test  Loss: 0.7868  | Test  Acc: 73.10%\n",
      "--------------------------------------------------\n",
      "Epoch [47/50]\n",
      "  Train Loss: 0.8302 | Train Acc: 71.09%\n",
      "  Test  Loss: 0.8149  | Test  Acc: 71.46%\n",
      "--------------------------------------------------\n",
      "Epoch [48/50]\n",
      "  Train Loss: 0.8294 | Train Acc: 71.48%\n",
      "  Test  Loss: 0.7684  | Test  Acc: 73.05%\n",
      "--------------------------------------------------\n",
      "Epoch [49/50]\n",
      "  Train Loss: 0.8243 | Train Acc: 71.47%\n",
      "  Test  Loss: 0.7946  | Test  Acc: 72.61%\n",
      "--------------------------------------------------\n",
      "Epoch [50/50]\n",
      "  Train Loss: 0.8088 | Train Acc: 71.91%\n",
      "  Test  Loss: 0.8092  | Test  Acc: 72.19%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data loading with augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define SqueezeNet-based model for CIFAR-10\n",
    "from torchvision.models import squeezenet1_0\n",
    "\n",
    "model = squeezenet1_0(weights=None, num_classes=10)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# Training Function\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        total_correct += preds.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    return total_loss / total_samples, 100.0 * total_correct / total_samples\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            total_correct += preds.eq(labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    return total_loss / total_samples, 100.0 * total_correct / total_samples\n",
    "\n",
    "# Main Training Loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Test  Loss: {test_loss:.4f}  | Test  Acc: {test_acc:.2f}%\")\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c2f323-71e6-46c9-aa7e-b367fc4f0d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using device: mps\n",
      "Epoch [1/50]\n",
      "  Train Loss: 1.7831 | Train Acc: 33.38%\n",
      "  Test  Loss: 1.4696  | Test  Acc: 46.00%\n",
      "--------------------------------------------------\n",
      "Epoch [2/50]\n",
      "  Train Loss: 1.3720 | Train Acc: 50.03%\n",
      "  Test  Loss: 1.2785  | Test  Acc: 54.73%\n",
      "--------------------------------------------------\n",
      "Epoch [3/50]\n",
      "  Train Loss: 1.2015 | Train Acc: 56.73%\n",
      "  Test  Loss: 1.1287  | Test  Acc: 58.98%\n",
      "--------------------------------------------------\n",
      "Epoch [4/50]\n",
      "  Train Loss: 1.0716 | Train Acc: 61.86%\n",
      "  Test  Loss: 1.0290  | Test  Acc: 63.53%\n",
      "--------------------------------------------------\n",
      "Epoch [5/50]\n",
      "  Train Loss: 0.9769 | Train Acc: 65.16%\n",
      "  Test  Loss: 0.9376  | Test  Acc: 66.05%\n",
      "--------------------------------------------------\n",
      "Epoch [6/50]\n",
      "  Train Loss: 0.9116 | Train Acc: 67.61%\n",
      "  Test  Loss: 0.8910  | Test  Acc: 68.60%\n",
      "--------------------------------------------------\n",
      "Epoch [7/50]\n",
      "  Train Loss: 0.8547 | Train Acc: 69.65%\n",
      "  Test  Loss: 0.8842  | Test  Acc: 69.39%\n",
      "--------------------------------------------------\n",
      "Epoch [8/50]\n",
      "  Train Loss: 0.8064 | Train Acc: 71.54%\n",
      "  Test  Loss: 0.8289  | Test  Acc: 70.69%\n",
      "--------------------------------------------------\n",
      "Epoch [9/50]\n",
      "  Train Loss: 0.7653 | Train Acc: 73.07%\n",
      "  Test  Loss: 0.7919  | Test  Acc: 71.93%\n",
      "--------------------------------------------------\n",
      "Epoch [10/50]\n",
      "  Train Loss: 0.7212 | Train Acc: 74.78%\n",
      "  Test  Loss: 0.7195  | Test  Acc: 74.61%\n",
      "--------------------------------------------------\n",
      "Epoch [11/50]\n",
      "  Train Loss: 0.6989 | Train Acc: 75.51%\n",
      "  Test  Loss: 0.7144  | Test  Acc: 75.24%\n",
      "--------------------------------------------------\n",
      "Epoch [12/50]\n",
      "  Train Loss: 0.6708 | Train Acc: 76.59%\n",
      "  Test  Loss: 0.6875  | Test  Acc: 76.01%\n",
      "--------------------------------------------------\n",
      "Epoch [13/50]\n",
      "  Train Loss: 0.6383 | Train Acc: 77.67%\n",
      "  Test  Loss: 0.6729  | Test  Acc: 76.66%\n",
      "--------------------------------------------------\n",
      "Epoch [14/50]\n",
      "  Train Loss: 0.6223 | Train Acc: 78.14%\n",
      "  Test  Loss: 0.6294  | Test  Acc: 78.17%\n",
      "--------------------------------------------------\n",
      "Epoch [15/50]\n",
      "  Train Loss: 0.5997 | Train Acc: 79.04%\n",
      "  Test  Loss: 0.6701  | Test  Acc: 77.02%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 171\u001b[0m\n\u001b[1;32m    169\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 171\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[1;32m    172\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 131\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    129\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 131\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    132\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    133\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m, in \u001b[0;36mSqueezeNetCIFAR.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 103\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    104\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m, in \u001b[0;36mFireModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze_activation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze_bn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze(x)))\n\u001b[0;32m---> 68\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_activation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_bn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand1x1(x)))\n\u001b[1;32m     69\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_activation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_bn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand3x3(x)))\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([x1, x3], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2484\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "########################################\n",
    "# 1. Data Loading for CIFAR-10\n",
    "########################################\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "########################################\n",
    "# 2. Define the Fire Module (Your Implementation)\n",
    "########################################\n",
    "\n",
    "class FireModule(nn.Module):\n",
    "    def __init__(self, in_channels, sq, exp1, exp3):\n",
    "        super(FireModule, self).__init__()\n",
    "        if sq >= (exp1 + exp3):\n",
    "            raise ValueError(f\"Invalid FireModule: squeeze ({sq}) must be smaller than expand ({exp1 + exp3}).\")\n",
    "        \n",
    "        self.squeeze = nn.Conv2d(in_channels, sq, kernel_size=1, bias=False)\n",
    "        self.squeeze_bn = nn.BatchNorm2d(sq)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.expand1x1 = nn.Conv2d(sq, exp1, kernel_size=1, bias=False)\n",
    "        self.expand3x3 = nn.Conv2d(sq, exp3, kernel_size=3, padding=1, bias=False)\n",
    "        self.expand_bn1 = nn.BatchNorm2d(exp1)\n",
    "        self.expand_bn3 = nn.BatchNorm2d(exp3)\n",
    "        self.expand_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.squeeze.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.expand1x1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.expand3x3.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze_bn(self.squeeze(x)))\n",
    "        x1 = self.expand_activation(self.expand_bn1(self.expand1x1(x)))\n",
    "        x3 = self.expand_activation(self.expand_bn3(self.expand3x3(x)))\n",
    "        return torch.cat([x1, x3], dim=1)\n",
    "\n",
    "########################################\n",
    "# 3. Define a SqueezeNet Variant for CIFAR-10\n",
    "########################################\n",
    "\n",
    "class SqueezeNetCIFAR(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            FireModule(64, 16, 64, 64),\n",
    "            FireModule(128, 16, 64, 64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            FireModule(128, 32, 128, 128),\n",
    "            FireModule(256, 32, 128, 128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            FireModule(256, 48, 192, 192),\n",
    "            FireModule(384, 48, 192, 192),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            FireModule(384, 64, 256, 256),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "########################################\n",
    "# 4. Instantiate Model, Loss, Optimizer\n",
    "########################################\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = SqueezeNetCIFAR(num_classes=10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "########################################\n",
    "# 5. Training and Evaluation Functions\n",
    "########################################\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        total_correct += preds.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            total_correct += preds.eq(labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "########################################\n",
    "# 6. Main Training Loop\n",
    "########################################\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Test  Loss: {test_loss:.4f}  | Test  Acc: {test_acc:.2f}%\")\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33a6fd-3e30-499e-87c3-5553250959f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
